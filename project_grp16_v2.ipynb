{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nproject_grp16_v2.ipynb\\nThis notebook performs data analysis on the SnackChain dataset, demonstrating\\ncleaning, exploratory data analysis, and modeling steps.\\n'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "project_grp16_v2.ipynb\n",
    "This notebook performs data analysis on the SnackChain dataset, demonstrating\n",
    "cleaning, exploratory data analysis, and modeling steps.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently in use\n",
    "import re                               # Extraction of text\n",
    "import pandas as pd                     # Data manipulation\n",
    "import numpy as np                      # Numeric computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean 'stores.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the stores.xlsx file\n",
    "df_stores = pd.read_excel('stores.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column headers to lowercase\n",
    "df_stores.columns = df_stores.columns.str.lower()\n",
    "# Convert column data to lower case\n",
    "df_stores = df_stores.map(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean 'products.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the products.xlsx file\n",
    "df_products = pd.read_excel('products.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column headers to lower case\n",
    "df_products.columns = df_products.columns.str.lower()\n",
    "# Convert column data to lower case\n",
    "df_products = df_products.map(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean 'transactions.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the transactions.xlsx file\n",
    "df_transactions = pd.read_excel('transactions.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column headers to lower case\n",
    "df_transactions.columns = df_transactions.columns.str.lower()\n",
    "# Convert column data to lower case\n",
    "df_transactions = df_transactions.map(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Oral Hygiene Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean copy of the dataframe to avoid chained assignment warnings\n",
    "df_prod_cln = df_products[df_products['category'] != 'oral hygiene products'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'oral hygiene products' based on UPCs in df_prod_cln \n",
    "# The products df only without the oral hygiene products)\n",
    "keep_upcs = df_prod_cln['upc'].unique()\n",
    "\n",
    "# Only keep the UPCs in df_prod_cln\n",
    "df_trans_cln =df_transactions[df_transactions['upc'].isin(keep_upcs)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Product Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   size_value size_unit  size_in_ml\n",
      "0       15.00        oz  443.602500\n",
      "1       15.00        oz  443.602500\n",
      "2       15.00        oz  443.602500\n",
      "6       12.25        oz  362.275375\n",
      "7       20.00        oz  591.470000\n"
     ]
    }
   ],
   "source": [
    "# Function to extract numeric value and unit using regex\n",
    "def extract_size_details(size):\n",
    "    \"\"\"\n",
    "    Extracts a numeric value and unit from a product_size string using regex.\n",
    "    \n",
    "    Args:\n",
    "        size (str): A string representing the product size (e.g., \"15 OZ\", \"1.5 LT\").\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series: A pandas Series containing the extracted value (float) and unit (str).\n",
    "    \"\"\"\n",
    "    if isinstance(size, str):\n",
    "        match = re.match(r\"(\\d*\\.?\\d+)\\s*([a-zA-Z]+)\", size)  # Extract number and unit\n",
    "        if match:\n",
    "            return pd.Series([float(match.group(1)), match.group(2).lower()])\n",
    "    return pd.Series([None, None])  # Handle missing or incorrect formats\n",
    "# Apply function to extract size and unit safely\n",
    "df_prod_cln[['size_value', 'size_unit']] = df_prod_cln['product_size'].apply(\n",
    "    extract_size_details)\n",
    "# Define conversion rates in a dictionary\n",
    "conversion_rates = {\"ml\": 1, \"oz\": 29.5735, \"lt\": 1000}\n",
    "\n",
    "df_prod_cln['size_in_ml'] = df_prod_cln.apply(\n",
    "    lambda row: row['size_value'] * conversion_rates.get(row['size_unit'], np.nan)\n",
    "    if pd.notna(row['size_value']) and pd.notna(row['size_unit']) else np.nan, axis=1\n",
    ")\n",
    "# Drop the original product_size column since it's no longer needed\n",
    "df_prod_cln.drop(columns=['product_size'], inplace=True)\n",
    "# Debug: Check conversion results\n",
    "print(df_prod_cln[['size_value', 'size_unit', 'size_in_ml']].head())\n",
    "# Verify if any unknown units exist\n",
    "unknown_units = df_prod_cln[~df_prod_cln['size_unit'].isin(conversion_rates.keys()) &\n",
    "                            df_prod_cln['size_unit'].notna()]\n",
    "if not unknown_units.empty:\n",
    "    print(\"\\n Unknown Units Found:\\n\", unknown_units['size_unit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique size_value count: 25\n",
      "Unique size_unit count: 1\n",
      "Unique size_in_ml count: 25\n"
     ]
    }
   ],
   "source": [
    "# Count unique values in each column\n",
    "unique_size_value = df_prod_cln['size_value'].nunique(dropna=True)\n",
    "unique_size_unit = df_prod_cln['size_unit'].nunique(dropna=True)\n",
    "unique_size_in_ml = df_prod_cln['size_in_ml'].nunique(dropna=True)\n",
    "\n",
    "# Display results\n",
    "print(f\"Unique size_value count: {unique_size_value}\")\n",
    "print(f\"Unique size_unit count: {unique_size_unit}\")\n",
    "print(f\"Unique size_in_ml count: {unique_size_in_ml}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          upc               description   manufacturer     category  \\\n",
      "0  1111009477    pl mini twist pretzels  private label   bag snacks   \n",
      "1  1111009497         pl pretzel sticks  private label   bag snacks   \n",
      "2  1111009507         pl twist pretzels  private label   bag snacks   \n",
      "6  1111085319  pl honey nut toastd oats  private label  cold cereal   \n",
      "7  1111085345            pl raisin bran  private label  cold cereal   \n",
      "\n",
      "        sub_category  size_value size_unit  size_in_ml  \n",
      "0           pretzels       15.00        oz  443.602500  \n",
      "1           pretzels       15.00        oz  443.602500  \n",
      "2           pretzels       15.00        oz  443.602500  \n",
      "6  all family cereal       12.25        oz  362.275375  \n",
      "7       adult cereal       20.00        oz  591.470000  \n"
     ]
    }
   ],
   "source": [
    "# Ensure product_size is gone\n",
    "df_prod_cln.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in df_stores:\n",
      "store_id               0\n",
      "store_name             0\n",
      "city                   0\n",
      "state                  0\n",
      "msa                    0\n",
      "segment                0\n",
      "parking               52\n",
      "size                   0\n",
      "avg_weekly_baskets     0\n",
      "unnamed: 9            79\n",
      "unnamed: 10           76\n",
      "dtype: int64\n",
      "------------------------\n",
      "\n",
      "Missing values in df_prod_cln:\n",
      "upc             0\n",
      "description     0\n",
      "manufacturer    0\n",
      "category        0\n",
      "sub_category    0\n",
      "size_value      0\n",
      "size_unit       0\n",
      "size_in_ml      0\n",
      "dtype: int64\n",
      "------------------------\n",
      "\n",
      "Missing values in df_trans_cln:\n",
      "week_end_date      0\n",
      "store_num          0\n",
      "upc                0\n",
      "units              0\n",
      "visits             0\n",
      "hhs                0\n",
      "spend              0\n",
      "price             10\n",
      "base_price       173\n",
      "feature            0\n",
      "display            0\n",
      "tpr_only           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values in all dataframes\n",
    "print(\"Missing values in df_stores:\")\n",
    "print(df_stores.isnull().sum())\n",
    "print('------------------------')\n",
    "print(\"\\nMissing values in df_prod_cln:\")\n",
    "print(df_prod_cln.isnull().sum())\n",
    "print('------------------------')\n",
    "print(\"\\nMissing values in df_trans_cln:\")\n",
    "print(df_trans_cln.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop COLUMNS: 'parking', 'unnamed: 9', and 'unnamed: 10'from df_stores (Parking values = 35%)\n",
    "df_stores.drop(columns=['parking', 'unnamed: 9', 'unnamed: 10'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z9/4yg2bxhd77z407m0mn8rmkdr0000gn/T/ipykernel_10010/3639009700.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trans_cln.dropna(subset=['price', 'base_price'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop ROWS with missing price and base_price values\n",
    "df_trans_cln.dropna(subset=['price', 'base_price'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in df_stores:\n",
      "store_id              0\n",
      "store_name            0\n",
      "city                  0\n",
      "state                 0\n",
      "msa                   0\n",
      "segment               0\n",
      "size                  0\n",
      "avg_weekly_baskets    0\n",
      "dtype: int64\n",
      "------------------------\n",
      "\n",
      "Missing values in df_prod_cln:\n",
      "upc             0\n",
      "description     0\n",
      "manufacturer    0\n",
      "category        0\n",
      "sub_category    0\n",
      "size_value      0\n",
      "size_unit       0\n",
      "size_in_ml      0\n",
      "dtype: int64\n",
      "------------------------\n",
      "\n",
      "Missing values in df_trans_cln:\n",
      "week_end_date    0\n",
      "store_num        0\n",
      "upc              0\n",
      "units            0\n",
      "visits           0\n",
      "hhs              0\n",
      "spend            0\n",
      "price            0\n",
      "base_price       0\n",
      "feature          0\n",
      "display          0\n",
      "tpr_only         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values in all dataframes\n",
    "print(\"Missing values in df_stores:\")\n",
    "print(df_stores.isnull().sum())\n",
    "print('------------------------')\n",
    "print(\"\\nMissing values in df_prod_cln:\")\n",
    "print(df_prod_cln.isnull().sum())\n",
    "print('------------------------')\n",
    "print(\"\\nMissing values in df_trans_cln:\")\n",
    "print(df_trans_cln.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Excel file name\n",
    "# output_filename = \"cleaned_data.xlsx\"\n",
    "\n",
    "# # Write the DataFrames to separate sheets in one Excel file\n",
    "# with pd.ExcelWriter(output_filename, engine='auto') as writer:\n",
    "#     df_stores.to_excel(writer, sheet_name=\"Stores\", index=False)\n",
    "#     df_prod_cln.to_excel(writer, sheet_name=\"Products\", index=False)\n",
    "#     df_trans_cln.to_excel(writer, sheet_name=\"Transactions\", index=False)\n",
    "\n",
    "# print(f\"Excel file '{output_filename}' has been created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('I made thiis change')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
